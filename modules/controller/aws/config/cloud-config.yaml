#cloud-config
coreos:
  update:
    reboot-strategy: off

  etcd2:
    name: ${instance_name}
    data_dir: /var/lib/etcd/data

    initial_cluster: ${etcd_peers}
    initial_cluster_state: new

    initial_advertise_peer_urls: https://$private_ipv4:2380
    listen_peer_urls: https://0.0.0.0:2380
    advertise_client_urls: https://$private_ipv4:2379
    listen_client_urls: https://0.0.0.0:2379

    peer_cert_file: /etc/ssl/cluster/instance/cert.pem
    peer_key_file: /etc/ssl/cluster/instance/privkey.pem
    peer_trusted_ca_file: /etc/ssl/cluster/ca.pem
    peer_client_cert_auth: true

    cert_file: /etc/ssl/cluster/instance/cert.pem
    key_file: /etc/ssl/cluster/instance/privkey.pem
    trusted_ca_file: /etc/ssl/cluster/ca.pem
    client_cert_auth: true

  flannel:
    etcd_cafile: /etc/ssl/cluster/ca.pem
    etcd_keyfile: /etc/ssl/cluster/instance/privkey.pem
    etcd_certfile: /etc/ssl/cluster/instance/cert.pem
    etcd_endpoints: https://$private_ipv4:2379

  units:
    - name: ssh-helper.service
      command: start
      content: |
        [Service]
        Type=oneshot
        ExecStart=/opt/bin/install-ssh-helper.sh

    - name: cluster-ca.service
      command: start
      content: |
        [Service]
        Type=oneshot
        ExecStart=/opt/bin/install-cluster-ca.sh

    - name: vault-login.service
      command: start
      content: |
        [Service]
        Type=oneshot
        RemainAfterExit=yes
        ExecStart=/opt/bin/vault-login.sh

    - name: vault-renew-token.service
      content: |
        [Service]
        Type=simple
        ExecStart=/opt/bin/vault-renew.sh

    - name: vault-renew-token.timer
      command: start
      content: |
        [Timer]
        OnActiveSec=12h
        OnUnitActiveSec=12h

    - name: vault-certs.timer
      command: start
      content: |
        [Timer]
        OnUnitActiveSec=12h

    - name: vault-certs.service
      command: start
      content: |
        [Unit]
        Before=etcd2.service
        Before=flanneld.service
        Before=kubelet.service

        Requires=vault-login.service
        After=vault-login.service

        [Service]
        Type=simple

        ExecStart=/opt/bin/vault-certs.sh
        ExecStartPost=/bin/bash -c "systemctl kill -s HUP etcd2.service flanneld.service kubelet.service || true"
        ExecStartPost=/bin/bash -c "docker restart $(docker ps --format {{.Names}} | grep kube-apiserver) || true"
        ExecStartPost=/bin/bash -c "docker restart $(docker ps --format {{.Names}} | grep kube-flannel-server) || true"
        ExecStartPost=/bin/bash -c "docker restart $(docker ps --format {{.Names}} | grep kube-addon-manager-podmaster) || true"

    - name: kube-service-account.service
      command: start
      content: |
        [Unit]
        Before=kubelet.service

        Requires=vault-login.service
        After=vault-login.service

        [Service]
        Type=oneshot
        ExecStart=/opt/bin/service-account-certs.sh
        ExecStartPost=/bin/bash -c "docker restart $(docker ps --format {{.Names}} | grep kube-apiserver) || true"
        ExecStartPost=/bin/bash -c "docker restart $(docker ps --format {{.Names}} | grep kube-controller-manager) || true"

    - name: docker.service
      command: start
      drop-ins:
        - name: 99-mount-flags.conf
          content: |
            [Unit]
            After=flanneld.service
            [Service]
            MountFlags=shared

    - name: awscli.service
      command: start
      content: |
        [Unit]
        Requires=docker.service
        After=docker.service

        [Service]
        Type=oneshot
        Environment=DOCKER_CONTENT_TRUST=1
        ExecStart=/usr/bin/docker build -t localhost/awscli /opt/awscli/

    - name: ecr-login.service
      command: start
      content: |
        [Unit]
        Requires=awscli.service
        After=awscli.service

        [Service]
        Type=simple
        ExecStart=/bin/bash -c "\
          eval $(docker run --rm -e AWS_DEFAULT_REGION=${region} localhost/awscli ecr get-login)"

    - name: ecr-login.timer
      command: start
      content: |
        [Timer]
        OnUnitActiveSec=12h

    - name: dev-xvdb-format.service
      command: start
      content: |
        [Unit]
        Requires=dev-xvdb.device
        After=dev-xvdb.device

        Before=var-lib-etcd.mount
        ConditionPathExists=!/var/lib/etcd.formatted

        [Service]
        Type=oneshot
        ExecStart=/usr/sbin/wipefs -f /dev/xvdb
        ExecStart=/bin/bash -c "mkfs.ext4 -E root_owner=$(id -u etcd):$(id -u etcd) /dev/xvdb"
        ExecStartPost=/bin/touch /var/lib/etcd.formatted

    - name: var-lib-etcd.mount
      command: start
      content: |
        [Unit]
        Requires=dev-xvdb-format.service
        After=dev-xvbd-format.service

        Before=etcd2.service

        [Mount]
        What=/dev/xvdb
        Where=/var/lib/etcd
        Type=ext4

    - name: etcd2.service
      command: start
      drop-ins:
        - name: 99-options.conf
          content: |
            [Unit]
            Before=flanneld.service
            Requires=var-lib-etcd.mount
            After=var-lib-etcd.mount

            [Service]
            Restart=always
            RestartSec=10

            ExecStartPre=/usr/bin/test -s /etc/ssl/cluster/ca.pem
            ExecStartPre=/usr/bin/test -s /etc/ssl/cluster/instance/cert.pem
            ExecStartPre=/usr/bin/test -s /etc/ssl/cluster/instance/privkey.pem

    - name: flanneld.service
      command: start
      drop-ins:
        - name: 40-ssl-config.conf
          content: |
            Environment=ETCD_SSL_DIR=/etc/ssl/cluster/

            ExecStartPre=/usr/bin/test -s /etc/ssl/cluster/ca.pem
            ExecStartPre=/usr/bin/test -s /etc/ssl/cluster/instance/cert.pem
            ExecStartPre=/usr/bin/test -s /etc/ssl/cluster/instance/privkey.pem

        - name: 50-network-config.conf
          content: |
            [Unit]
            Before=docker.service
            Requires=etcd2.service
            After=etcd2.service

            [Service]
            ExecStartPre=/usr/bin/etcdctl \
              --endpoints https://$private_ipv4:2379 \
              --ca-file /etc/ssl/cluster/ca.pem \
              --cert-file /etc/ssl/cluster/instance/cert.pem \
              --key-file /etc/ssl/cluster/instance/privkey.pem \
              set /coreos.com/network/config \
                '{ "Network": "10.10.0.0/16", "Backend": { "Type": "vxlan" } }'

    - name: kubelet.service
      command: start
      content: |
        [Unit]
        Requires=docker.service etcd2.service flanneld.service
        After=docker.service etcd2.service flanneld.service

        [Service]
        Restart=always
        RestartSec=10
        TimeoutStartSec=300

        ExecStartPre=/usr/bin/docker pull ${hyperkube}
        ExecStartPre=/usr/bin/test -s /etc/ssl/cluster/ca.pem
        ExecStartPre=/usr/bin/test -s /etc/ssl/cluster/instance/cert.pem
        ExecStartPre=/usr/bin/test -s /etc/ssl/cluster/instance/privkey.pem
        ExecStartPre=/usr/bin/test -s /etc/kubernetes/service-account/pubkey.pem
        ExecStartPre=/usr/bin/test -s /etc/kubernetes/service-account/privkey.pem

        ExecStart=/usr/bin/docker run --net=host --pid=host --privileged \
          -v /:/rootfs:ro \
          -v /sys/:/sys/ \
          -v /dev/:/dev/ \
          -v /var/run/:/var/run/ \
          -v /var/log/:/var/log/ \
          -v /var/lib/docker/:/var/lib/docker/ \
          -v /var/lib/kubelet/:/var/lib/kubelet/:shared \
          -v /etc/ssl/cluster/:/etc/ssl/cluster/ \
          -v /etc/kubernetes/:/etc/kubernetes/ \
          ${hyperkube} \
            /hyperkube kubelet \
              --containerized \
              --api-servers=https://${fqdn} \
              --node-labels=role=controller \
              --cloud-provider=aws \
              --tls-cert-file=/etc/ssl/cluster/instance/cert.pem \
              --tls-private-key-file=/etc/ssl/cluster/instance/privkey.pem \
              --register-schedulable=false \
              --config=/etc/kubernetes/manifests \
              --kubeconfig=/etc/kubernetes/kubeconfig.yaml \
              --cluster-dns=10.0.0.10 \
              --cluster-domain=cluster.local \
              --allow-privileged --v=2 --logtostderr=true

write_files:
  - path: /opt/awscli/Dockerfile
    content: |
      FROM alpine:3.4

      RUN mkdir -p /aws && \
        apk -Uuv add groff less python py-pip jq && \
        pip install awscli && \
        apk --purge -v del py-pip && \
        rm /var/cache/apk/*

      WORKDIR /aws
      ENTRYPOINT ["aws"]

  - path: /opt/bin/ssh-helper
    permissions: 0700
    content: |
      #! /bin/bash
      CMD="docker run -i --rm --net=host -e PAM_USER=$PAM_USER ${ssh_helper}"
      eval $CMD $*

  - path: /opt/bin/install-ssh-helper.sh
    permissions: 0700
    content: |
      #!/bin/bash
      set -e
      log="/var/log/vault-ssh.log"
      replace="auth\t\tsufficient\tpam_exec.so quiet expose_authtok log=$log /opt/bin/ssh-helper"
      cp /usr/lib64/pam.d/{sshd,system-remote-login,system-login,system-auth} /etc/pam.d/
      sed -r -i /etc/pam.d/system-auth -e "s,^(auth.*required.*pam_deny.so)$,$replace\\n\1,g"

  - path: /opt/bin/install-cluster-ca.sh
    permissions: 0700
    content: |
      #!/bin/bash
      set -e

      mkdir -p /etc/ssl/cluster
      curl -sSf -o /etc/ssl/cluster/ca.pem ${vault_address}/v1/${vault_pki_mount}/ca/pem

  - path: /opt/bin/vault-login.sh
    permissions: 0700
    content: |
      #!/bin/bash
      set -e

      role="${vault_instance_role}"
      pkcs="$(curl -sSf http://169.254.169.254/latest/dynamic/instance-identity/pkcs7 | tr -d '\n')"
      nonce="$(cat /etc/machine-id | base64)"

      curl -sSf -X POST \
        -H "Content-Type: application/json" \
        -d "{\"pkcs7\": \"$pkcs\", \"role\": \"$role\", \"nonce\":\"$nonce\"}" \
        ${vault_address}/v1/auth/aws-ec2/login | \
        sed -re 's/.*"client_token":"([^"]*)".*/\1/g' > /root/.vault-token

  - path: /opt/bin/vault-renew.sh
    permissions: 0700
    content: |
      #!/bin/bash

      curl -sSf -X POST -H "X-Vault-Token: $(cat /root/.vault-token)" \
        ${vault_address}/v1/auth/token/renew-self > /dev/null

  - path: /opt/bin/vault-certs.sh
    permissions: 0700
    content: |
      #!/bin/bash
      set -e

      cn="${fqdn}"
      san="$(hostname),controller,kubernetes,kubernetes.default,kubernetes.default.svc,kubernetes.default.svc.cluster.local"
      ipsan="10.0.0.1,$private_ipv4"

      json=$(curl -sSf -X POST -H "X-Vault-Token: $(cat /root/.vault-token)" \
        -d "{\"common_name\":\"$cn\", \"alt_names\":\"$san\", \"ip_sans\": \"$ipsan\"}" \
        ${vault_address}/v1/${vault_pki_mount}/issue/${vault_pki_role})

      mkdir -p /etc/ssl/cluster/instance
      echo "$json" | \
        sed -re 's/.*"certificate":"([^"]*)".*/\1/g' -e 's/\\n/\n/g' \
        > /etc/ssl/cluster/instance/cert.pem
      echo "$json" | \
        sed -re 's/.*"private_key":"([^"]*)".*/\1/g' -e 's/\\n/\n/g' \
        > /etc/ssl/cluster/instance/privkey.pem

  - path: /opt/bin/service-account-certs.sh
    permissions: 0700
    content: |
      #!/bin/bash
      set -e

      json=$(curl -sSf -X GET -H "X-Vault-Token: $(cat /root/.vault-token)" \
        ${vault_address}/v1/${service_account_path})

      mkdir -p /etc/kubernetes/service-account
      echo "$json" | \
        sed -re 's/.*"public_key":"([^"]*)".*/\1/g' -e 's/\\n/\n/g' \
        > /etc/kubernetes/service-account/pubkey.pem
      echo "$json" | \
        sed -re 's/.*"private_key":"([^"]*)".*/\1/g' -e 's/\\n/\n/g' \
        > /etc/kubernetes/service-account/privkey.pem

  - path: /etc/kubernetes/kubeconfig.yaml
    content: |
      apiVersion: v1
      kind: Config
      current-context: controller
      clusters:
        - name: kubernetes
          cluster:
            certificate-authority: /etc/ssl/cluster/ca.pem
            server: https://${fqdn}
      contexts:
        - name: controller
          context:
            cluster: kubernetes
            user: controller
      users:
        - name: controller
          user:
            client-certificate: /etc/ssl/cluster/instance/cert.pem
            client-key: /etc/ssl/cluster/instance/privkey.pem

  - path: /etc/kubernetes/manifests/kube-apiserver.yaml
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-apiserver
        namespace: kube-system
        labels:
          app: kubernetes
          component: apiserver
      spec:
        hostNetwork: true
        imagePullPolicy: Always
        containers:
          - name: kube-apiserver
            image: ${hyperkube}
            command:
              - /hyperkube
              - apiserver
              - --secure-port=443
              - --etcd-servers=https://$private_ipv4:2379
              - --etcd-cafile=/etc/ssl/cluster/ca.pem
              - --etcd-certfile=/etc/ssl/cluster/instance/cert.pem
              - --etcd-keyfile=/etc/ssl/cluster/instance/privkey.pem
              - --tls-cert-file=/etc/ssl/cluster/instance/cert.pem
              - --tls-private-key-file=/etc/ssl/cluster/instance/privkey.pem
              - --service-account-key-file=/etc/kubernetes/service-account/pubkey.pem
              - --kubelet-certificate-authority=/etc/ssl/cluster/ca.pem
              - --kubelet-client-certificate=/etc/ssl/cluster/instance/cert.pem
              - --kubelet-client-key=/etc/ssl/cluster/instance/privkey.pem
              - --allow-privileged=true
              - --client-ca-file=/etc/ssl/cluster/ca.pem
              - --service-cluster-ip-range=10.0.0.0/16
              - --advertise-address=$private_ipv4
              - --external-hostname=${fqdn}
              - --oidc-issuer-url=${oidc_issuer_url}
              - --oidc-client-id=${oidc_client_id}
              - --oidc-username-claim=${oidc_username_claim}
              - --oidc-groups-claim=${oidc_groups_claim}
              - --authorization-mode=AlwaysAllow
              - --admission-control=NamespaceLifecycle,LimitRanger,ServiceAccount,ResourceQuota,DenyEscalatingExec,ServiceAccount
              - --runtime-config=extensions/v1beta1/deployments=true,extensions/v1beta1/daemonsets=true,extensions/v1beta1=true,extensions/v1beta1/thirdpartyresources=true
              - --cloud-provider=aws
            livenessProbe:
              httpGet:
                host: 127.0.0.1
                path: /healthz
                port: 8080
              initialDelaySeconds: 30
              timeoutSeconds: 1
            volumeMounts:
              - mountPath: /etc/kubernetes/service-account/pubkey.pem
                name: service-account
                readOnly: true
              - mountPath: /etc/ssl/cluster/
                name: cluster-certs
                readOnly: true
              - mountPath: /etc/ssl/certs
                name: ssl-certs-host
                readOnly: true
        volumes:
          - hostPath:
              path: /etc/kubernetes/controller
            name: ssl-certs-kubernetes
          - hostPath:
              path: /etc/kubernetes/service-account/pubkey.pem
            name: service-account
          - hostPath:
              path: /etc/ssl/cluster/
            name: cluster-certs
          - hostPath:
              path: /usr/share/ca-certificates
            name: ssl-certs-host

  - path: /etc/kubernetes/manifests/kube-controller-manager.yaml
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-controller-manager
        namespace: kube-system
        labels:
          app: kubernetes
          component: controller-manager
      spec:
        hostNetwork: true
        imagePullPolicy: Always
        containers:
          - name: kube-controller-manager
            image: ${hyperkube}
            command:
              - /hyperkube
              - controller-manager
              - --master=http://127.0.0.1:8080
              - --leader-elect=true
              - --cloud-provider=aws
              - --root-ca-file=/etc/ssl/cluster/ca.pem
              - --service-account-private-key-file=/etc/kubernetes/service-account/privkey.pem
            livenessProbe:
              httpGet:
                host: 127.0.0.1
                path: /healthz
                port: 10252
              initialDelaySeconds: 15
              timeoutSeconds: 1
            volumeMounts:
              - mountPath: /etc/ssl/cluster/ca.pem
                name: cluster-ca
                readOnly: true
              - mountPath: /etc/ssl/certs
                name: ssl-certs-host
                readOnly: true
              - mountPath: /etc/kubernetes/service-account/privkey.pem
                name: service-account
                readOnly: true
        volumes:
          - hostPath:
              path: /usr/share/ca-certificates
            name: ssl-certs-host
          - hostPath:
              path: /etc/ssl/cluster/ca.pem
            name: cluster-ca
          - hostPath:
              path: /etc/kubernetes/service-account/privkey.pem
            name: service-account

  - path: /etc/kubernetes/manifests/kube-scheduler.yaml
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-scheduler
        namespace: kube-system
        labels:
          app: kubernetes
          component: scheduler
      spec:
        hostNetwork: true
        imagePullPolicy: Always
        containers:
          - name: kube-scheduler
            image: ${hyperkube}
            command:
              - /hyperkube
              - scheduler
              - --master=http://127.0.0.1:8080
              - --leader-elect=true
            livenessProbe:
              httpGet:
                host: 127.0.0.1
                path: /healthz
                port: 10251
              initialDelaySeconds: 15
              timeoutSeconds: 1

  - path: /etc/kubernetes/manifests/kube-flannel-server.yaml
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-flannel-server
        namespace: kube-system
        labels:
          k8s-app: flannel-server
          version: v1
      spec:
        hostNetwork: true
        imagePullPolicy: Always
        containers:
          - name: flannel-server
            image: quay.io/coreos/flannel:0.5.5
            command:
              - /opt/bin/flanneld
              - --listen=0.0.0.0:8888
              - --etcd-endpoints=https://$private_ipv4:2379
              - --etcd-cafile=/etc/ssl/cluster/ca.pem
              - --etcd-certfile=/etc/ssl/cluster/instance/cert.pem
              - --etcd-keyfile=/etc/ssl/cluster/instance/privkey.pem
              - --remote-cafile=/etc/ssl/cluster/ca.pem
              - --remote-certfile=/etc/ssl/cluster/instance/cert.pem
              - --remote-keyfile=/etc/ssl/cluster/instance/privkey.pem
            securityContext:
              privileged: true
            livenessProbe:
              tcpSocket:
                port: 8888
            volumeMounts:
              - mountPath: /etc/ssl/cluster
                name: cluster-certs
                readOnly: true
              - mountPath: /etc/ssl/certs
                name: ssl-certs-host
                readOnly: true
        volumes:
          - hostPath:
              path: /etc/kubernetes/service-account/pubkey.pem
            name: service-account
          - hostPath:
              path: /etc/ssl/cluster
            name: cluster-certs
          - hostPath:
              path: /usr/share/ca-certificates
            name: ssl-certs-host
